{
  "subtask1": {
    "ensemble": "Yes, multiple model outputs were combined for the turn detection",
    "pretrained": " gpt2,t5,roberta,electra,bert,phome-bert",
    "desc": "\nSub-task 1\n\n1. Data enhancement:\n\n   1.1: Add dialogue intention According to multi_woz 2.2 schama.json tag for data enhancement\n\n   1.2: Entity name replacement: count the label of the knowledge base that appears in the dialogue, count the frequency of each entity word, and ensure the data is evenly distributed. It is best to replace and enhance it with colloquial knowledge.\n\n   1.3.Question rewriting: Synonym rewrite the last sentence (user question). Strengthen matching generalization ability\n\n   1.4.Knowledge insertion: Insert as the original paper, and see all similar knowledge bases as much as possible\n\n   1.5.Perform speech synthesis on all dstc9 data, then perform data enhancement on the voice level, and then transcribe the ASR text, and post-process the asr text to ensure that the word accuracy of the training set used for training remains above 70% .\n\n Ensure that the proportions of all categories are balanced, especially attraction.\n\n2 Model pre-training:\n\n\u200b    2.1Perform pre-training tasks on the public asr data set based on the original pre-training model\n\n   2.2 Establish phoneme encoding and pre-train the model on the roberta model"
  },
  "subtask2": {
    "ensemble": "Yes, multiple model outputs were combined for the knowledge selection",
    "pretrained": " gpt2,t5,roberta,electra,bert,phome-bert",
    "desc": "Sub-task2\n\nSampling method:\n\n  1. Sample negative sampling: select similar samples from the knowledge base according to phoneme vector and literal vector respectively\n\n  2. Sample positive sampling: Generated based on ASR enhancement and nbest's transcription result\n\nTraining method:\n\n  1. Joint multi-task training: domain-entity-doc select multi-task training\n\n  2. Sort by stages: 1. pointwise roberta-base (entity track) to select all the included knowledge names, fuzzy matching + labeling model 2. pairwise bert-base joint negative sampling faq to select top5 3. Use listwise roberta again -base select top1\n\nTwo-way rerank: \n\n1. Starting from the name of the entity involved in the dialogue history, select the entity that has appeared according to the rules. 2. Select the topn entity. 3. Then select the best match.\n2. Starting from the intention of the last sentence, first know what type of question it is based on the last question. Then according to the faq question (inverted index) to find the corresponding entity. Select the most relevant entity in the entity."
  },
  "subtask3": {
    "ensemble": "No, only a single model was used for the response generation",
    "pretrained": "t5",
    "desc": "1.Generate response based on context+ uttrance_nbest1 + uttrance_nbest2 + ... + domain+faq\n\n   in order to answer the user\u2019s question in an accurate and informative manner, the response    usually contain parts of the knowledge snippet and the corresponding entity name,\nboth of which are given as inputs to the model. Therefore, we try adding a pointer network on top of T5 to encourage the model to copy words directly from the input, rather than selecting from a\nvast number of words from the vocabulary.\n\nIn this model, the pointer generator is extended and converted into three modes: (1) generate a word; (2) copy a word from the dialogue history; (3) copy a word from the facts.\n\nIn the end, the probability that the model generates a word is equal to the sum of the probabilities generated by the three modes\n\n2. The clustering Beam Search algorithm can dynamically group and classify similar semantic sequences during decoding, avoiding generating general responses\n\n3. Use post-processing for the generated response: Filter Meaningless Response using LM"
  }
}